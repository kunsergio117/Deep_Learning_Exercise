{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m wordnet \u001b[39mas\u001b[39;00m wn\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstem\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming using Porter stemmer\n",
    "def stem_sentence_porter(sentence):\n",
    "    stemmer = PorterStemmer()\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    stemmed_sentence = \" \".join(stemmer.stem(w) for w in words)\n",
    "    return stemmed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chines millionair to doubl by 2026 , credit suiss say , despit slow economi'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_sentence_porter(\"Chinese millionaires to double by 2026, Credit Suisse says, despite slowing economy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming using Snowball stemmer\n",
    "#Snowball stemmer is like Porter stemmer v2\n",
    "def stem_sentence_snowball(sentence):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    stemmed_sentence = \" \".join(stemmer.stem(w) for w in words)\n",
    "    return stemmed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chines millionair to doubl by 2026 , credit suiss say , despit slow economi'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_sentence_snowball(\"Chinese millionaires to double by 2026, Credit Suisse says, despite slowing economy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200\n",
    "def generate_syn_df(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    df = pd.DataFrame([{'Synset': synset,\n",
    "                         'Part of Speech': synset.lexname(),\n",
    "                         'Definition': synset.definition(),\n",
    "                         'Lemmas': synset.lemma_names(),\n",
    "                         'Examples': synset.examples()}\n",
    "                             for synset in synsets])\n",
    "    df = df[['Synset', 'Part of Speech', 'Definition', 'Lemmas', 'Examples']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Synset</th>\n",
       "      <th>Part of Speech</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Lemmas</th>\n",
       "      <th>Examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Synset('bank.n.01')</td>\n",
       "      <td>noun.object</td>\n",
       "      <td>sloping land (especially the slope beside a body of water)</td>\n",
       "      <td>[bank]</td>\n",
       "      <td>[they pulled the canoe up on the bank, he sat on the bank of the river and watched the currents]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Synset('depository_financial_institution.n.01')</td>\n",
       "      <td>noun.group</td>\n",
       "      <td>a financial institution that accepts deposits and channels the money into lending activities</td>\n",
       "      <td>[depository_financial_institution, bank, banking_concern, banking_company]</td>\n",
       "      <td>[he cashed a check at the bank, that bank holds the mortgage on my home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Synset('bank.n.03')</td>\n",
       "      <td>noun.object</td>\n",
       "      <td>a long ridge or pile</td>\n",
       "      <td>[bank]</td>\n",
       "      <td>[a huge bank of earth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Synset('bank.n.04')</td>\n",
       "      <td>noun.group</td>\n",
       "      <td>an arrangement of similar objects in a row or in tiers</td>\n",
       "      <td>[bank]</td>\n",
       "      <td>[he operated a bank of switches]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Synset('bank.n.05')</td>\n",
       "      <td>noun.possession</td>\n",
       "      <td>a supply or stock held in reserve for future use (especially in emergencies)</td>\n",
       "      <td>[bank]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Synset('bank.n.06')</td>\n",
       "      <td>noun.possession</td>\n",
       "      <td>the funds held by a gambling house or the dealer in some gambling games</td>\n",
       "      <td>[bank]</td>\n",
       "      <td>[he tried to break the bank at Monte Carlo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Synset('bank.n.07')</td>\n",
       "      <td>noun.object</td>\n",
       "      <td>a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force</td>\n",
       "      <td>[bank, cant, camber]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Synset('savings_bank.n.02')</td>\n",
       "      <td>noun.artifact</td>\n",
       "      <td>a container (usually with a slot in the top) for keeping money at home</td>\n",
       "      <td>[savings_bank, coin_bank, money_box, bank]</td>\n",
       "      <td>[the coin bank was empty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Synset('bank.n.09')</td>\n",
       "      <td>noun.artifact</td>\n",
       "      <td>a building in which the business of banking transacted</td>\n",
       "      <td>[bank, bank_building]</td>\n",
       "      <td>[the bank is on the corner of Nassau and Witherspoon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Synset('bank.n.10')</td>\n",
       "      <td>noun.act</td>\n",
       "      <td>a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)</td>\n",
       "      <td>[bank]</td>\n",
       "      <td>[the plane went into a steep bank]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Synset('bank.v.01')</td>\n",
       "      <td>verb.motion</td>\n",
       "      <td>tip laterally</td>\n",
       "      <td>[bank]</td>\n",
       "      <td>[the pilot had to bank the aircraft]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Synset('bank.v.02')</td>\n",
       "      <td>verb.contact</td>\n",
       "      <td>enclose with a bank</td>\n",
       "      <td>[bank]</td>\n",
       "      <td>[bank roads]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Synset('bank.v.03')</td>\n",
       "      <td>verb.possession</td>\n",
       "      <td>do business with a bank or keep an account at a bank</td>\n",
       "      <td>[bank]</td>\n",
       "      <td>[Where do you bank in this town?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Synset('bank.v.04')</td>\n",
       "      <td>verb.possession</td>\n",
       "      <td>act as the banker in a game or in gambling</td>\n",
       "      <td>[bank]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Synset('bank.v.05')</td>\n",
       "      <td>verb.possession</td>\n",
       "      <td>be in the banking business</td>\n",
       "      <td>[bank]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Synset('deposit.v.02')</td>\n",
       "      <td>verb.possession</td>\n",
       "      <td>put into a bank account</td>\n",
       "      <td>[deposit, bank]</td>\n",
       "      <td>[She deposits her paycheck every month]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Synset('bank.v.07')</td>\n",
       "      <td>verb.contact</td>\n",
       "      <td>cover with ashes so to control the rate of burning</td>\n",
       "      <td>[bank]</td>\n",
       "      <td>[bank a fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Synset('trust.v.01')</td>\n",
       "      <td>verb.cognition</td>\n",
       "      <td>have confidence or faith in</td>\n",
       "      <td>[trust, swear, rely, bank]</td>\n",
       "      <td>[We can trust in God, Rely on your friends, bank on your good education, I swear by my grandmother's recipes]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Synset   Part of Speech  \\\n",
       "0                               Synset('bank.n.01')      noun.object   \n",
       "1   Synset('depository_financial_institution.n.01')       noun.group   \n",
       "2                               Synset('bank.n.03')      noun.object   \n",
       "3                               Synset('bank.n.04')       noun.group   \n",
       "4                               Synset('bank.n.05')  noun.possession   \n",
       "5                               Synset('bank.n.06')  noun.possession   \n",
       "6                               Synset('bank.n.07')      noun.object   \n",
       "7                       Synset('savings_bank.n.02')    noun.artifact   \n",
       "8                               Synset('bank.n.09')    noun.artifact   \n",
       "9                               Synset('bank.n.10')         noun.act   \n",
       "10                              Synset('bank.v.01')      verb.motion   \n",
       "11                              Synset('bank.v.02')     verb.contact   \n",
       "12                              Synset('bank.v.03')  verb.possession   \n",
       "13                              Synset('bank.v.04')  verb.possession   \n",
       "14                              Synset('bank.v.05')  verb.possession   \n",
       "15                           Synset('deposit.v.02')  verb.possession   \n",
       "16                              Synset('bank.v.07')     verb.contact   \n",
       "17                             Synset('trust.v.01')   verb.cognition   \n",
       "\n",
       "                                                                                                                           Definition  \\\n",
       "0                                                                          sloping land (especially the slope beside a body of water)   \n",
       "1                                        a financial institution that accepts deposits and channels the money into lending activities   \n",
       "2                                                                                                                a long ridge or pile   \n",
       "3                                                                              an arrangement of similar objects in a row or in tiers   \n",
       "4                                                        a supply or stock held in reserve for future use (especially in emergencies)   \n",
       "5                                                             the funds held by a gambling house or the dealer in some gambling games   \n",
       "6   a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force   \n",
       "7                                                              a container (usually with a slot in the top) for keeping money at home   \n",
       "8                                                                              a building in which the business of banking transacted   \n",
       "9                                      a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)   \n",
       "10                                                                                                                      tip laterally   \n",
       "11                                                                                                                enclose with a bank   \n",
       "12                                                                               do business with a bank or keep an account at a bank   \n",
       "13                                                                                         act as the banker in a game or in gambling   \n",
       "14                                                                                                         be in the banking business   \n",
       "15                                                                                                            put into a bank account   \n",
       "16                                                                                 cover with ashes so to control the rate of burning   \n",
       "17                                                                                                        have confidence or faith in   \n",
       "\n",
       "                                                                        Lemmas  \\\n",
       "0                                                                       [bank]   \n",
       "1   [depository_financial_institution, bank, banking_concern, banking_company]   \n",
       "2                                                                       [bank]   \n",
       "3                                                                       [bank]   \n",
       "4                                                                       [bank]   \n",
       "5                                                                       [bank]   \n",
       "6                                                         [bank, cant, camber]   \n",
       "7                                   [savings_bank, coin_bank, money_box, bank]   \n",
       "8                                                        [bank, bank_building]   \n",
       "9                                                                       [bank]   \n",
       "10                                                                      [bank]   \n",
       "11                                                                      [bank]   \n",
       "12                                                                      [bank]   \n",
       "13                                                                      [bank]   \n",
       "14                                                                      [bank]   \n",
       "15                                                             [deposit, bank]   \n",
       "16                                                                      [bank]   \n",
       "17                                                  [trust, swear, rely, bank]   \n",
       "\n",
       "                                                                                                         Examples  \n",
       "0                [they pulled the canoe up on the bank, he sat on the bank of the river and watched the currents]  \n",
       "1                                        [he cashed a check at the bank, that bank holds the mortgage on my home]  \n",
       "2                                                                                          [a huge bank of earth]  \n",
       "3                                                                                [he operated a bank of switches]  \n",
       "4                                                                                                              []  \n",
       "5                                                                     [he tried to break the bank at Monte Carlo]  \n",
       "6                                                                                                              []  \n",
       "7                                                                                       [the coin bank was empty]  \n",
       "8                                                           [the bank is on the corner of Nassau and Witherspoon]  \n",
       "9                                                                              [the plane went into a steep bank]  \n",
       "10                                                                           [the pilot had to bank the aircraft]  \n",
       "11                                                                                                   [bank roads]  \n",
       "12                                                                              [Where do you bank in this town?]  \n",
       "13                                                                                                             []  \n",
       "14                                                                                                             []  \n",
       "15                                                                        [She deposits her paycheck every month]  \n",
       "16                                                                                                  [bank a fire]  \n",
       "17  [We can trust in God, Rely on your friends, bank on your good education, I swear by my grandmother's recipes]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_syn_df(\"bank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Synset</th>\n",
       "      <th>Part of Speech</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Lemmas</th>\n",
       "      <th>Examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Synset('serve.n.01')</td>\n",
       "      <td>noun.act</td>\n",
       "      <td>(sports) a stroke that puts the ball in play</td>\n",
       "      <td>[serve, service]</td>\n",
       "      <td>[his powerful serves won the game]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Synset('serve.v.01')</td>\n",
       "      <td>verb.stative</td>\n",
       "      <td>serve a purpose, role, or function</td>\n",
       "      <td>[serve, function]</td>\n",
       "      <td>[The tree stump serves as a table, The female students served as a control group, This table would serve very well, His freedom served him well, The table functions as a desk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Synset('serve.v.02')</td>\n",
       "      <td>verb.competition</td>\n",
       "      <td>do duty or hold offices; serve in a specific function</td>\n",
       "      <td>[serve]</td>\n",
       "      <td>[He served as head of the department for three years, She served in Congress for two terms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Synset('serve.v.03')</td>\n",
       "      <td>verb.stative</td>\n",
       "      <td>contribute or conduce to</td>\n",
       "      <td>[serve]</td>\n",
       "      <td>[The scandal served to increase his popularity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Synset('service.v.01')</td>\n",
       "      <td>verb.social</td>\n",
       "      <td>be used by; as of a utility</td>\n",
       "      <td>[service, serve]</td>\n",
       "      <td>[The sewage plant served the neighboring communities, The garage served to shelter his horses]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Synset('serve.v.05')</td>\n",
       "      <td>verb.consumption</td>\n",
       "      <td>help to some food; help with food or drink</td>\n",
       "      <td>[serve, help]</td>\n",
       "      <td>[I served him three times, and after that he helped himself]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Synset('serve.v.06')</td>\n",
       "      <td>verb.consumption</td>\n",
       "      <td>provide (usually but not necessarily food)</td>\n",
       "      <td>[serve, serve_up, dish_out, dish_up, dish]</td>\n",
       "      <td>[We serve meals for the homeless, She dished out the soup at 8 P.M., The entertainers served up a lively show]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Synset('serve.v.07')</td>\n",
       "      <td>verb.social</td>\n",
       "      <td>devote (part of) one's life or efforts to, as of countries, institutions, or ideas</td>\n",
       "      <td>[serve]</td>\n",
       "      <td>[She served the art of music, He served the church, serve the country]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Synset('serve.v.08')</td>\n",
       "      <td>verb.stative</td>\n",
       "      <td>promote, benefit, or be useful or beneficial to</td>\n",
       "      <td>[serve, serve_well]</td>\n",
       "      <td>[Art serves commerce, Their interests are served, The lake serves recreation, The President's wisdom has served the country well]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Synset('serve.v.09')</td>\n",
       "      <td>verb.stative</td>\n",
       "      <td>spend time in prison or in a labor camp</td>\n",
       "      <td>[serve, do]</td>\n",
       "      <td>[He did six years for embezzlement]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Synset('serve.v.10')</td>\n",
       "      <td>verb.social</td>\n",
       "      <td>work for or be a servant to</td>\n",
       "      <td>[serve, attend_to, wait_on, attend, assist]</td>\n",
       "      <td>[May I serve you?, She attends the old lady in the wheelchair, Can you wait on our table, please?, Is a salesperson assisting you?, The minister served the King for many years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Synset('serve.v.11')</td>\n",
       "      <td>verb.contact</td>\n",
       "      <td>deliver a warrant or summons to someone</td>\n",
       "      <td>[serve, process, swear_out]</td>\n",
       "      <td>[He was processed by the sheriff]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Synset('suffice.v.01')</td>\n",
       "      <td>verb.stative</td>\n",
       "      <td>be sufficient; be adequate, either in quality or quantity</td>\n",
       "      <td>[suffice, do, answer, serve]</td>\n",
       "      <td>[A few words would answer, This car suits my purpose well, Will $100 do?, A 'B' grade doesn't suffice to get me into medical school, Nothing else will serve]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Synset('serve.v.13')</td>\n",
       "      <td>verb.social</td>\n",
       "      <td>do military service</td>\n",
       "      <td>[serve]</td>\n",
       "      <td>[She served in Vietnam, My sons never served, because they are short-sighted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Synset('serve.v.14')</td>\n",
       "      <td>verb.contact</td>\n",
       "      <td>mate with</td>\n",
       "      <td>[serve, service]</td>\n",
       "      <td>[male animals serve the females for breeding purposes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Synset('serve.v.15')</td>\n",
       "      <td>verb.competition</td>\n",
       "      <td>put the ball into play</td>\n",
       "      <td>[serve]</td>\n",
       "      <td>[It was Agassi's turn to serve]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Synset    Part of Speech  \\\n",
       "0     Synset('serve.n.01')          noun.act   \n",
       "1     Synset('serve.v.01')      verb.stative   \n",
       "2     Synset('serve.v.02')  verb.competition   \n",
       "3     Synset('serve.v.03')      verb.stative   \n",
       "4   Synset('service.v.01')       verb.social   \n",
       "5     Synset('serve.v.05')  verb.consumption   \n",
       "6     Synset('serve.v.06')  verb.consumption   \n",
       "7     Synset('serve.v.07')       verb.social   \n",
       "8     Synset('serve.v.08')      verb.stative   \n",
       "9     Synset('serve.v.09')      verb.stative   \n",
       "10    Synset('serve.v.10')       verb.social   \n",
       "11    Synset('serve.v.11')      verb.contact   \n",
       "12  Synset('suffice.v.01')      verb.stative   \n",
       "13    Synset('serve.v.13')       verb.social   \n",
       "14    Synset('serve.v.14')      verb.contact   \n",
       "15    Synset('serve.v.15')  verb.competition   \n",
       "\n",
       "                                                                            Definition  \\\n",
       "0                                         (sports) a stroke that puts the ball in play   \n",
       "1                                                   serve a purpose, role, or function   \n",
       "2                                do duty or hold offices; serve in a specific function   \n",
       "3                                                             contribute or conduce to   \n",
       "4                                                          be used by; as of a utility   \n",
       "5                                           help to some food; help with food or drink   \n",
       "6                                           provide (usually but not necessarily food)   \n",
       "7   devote (part of) one's life or efforts to, as of countries, institutions, or ideas   \n",
       "8                                      promote, benefit, or be useful or beneficial to   \n",
       "9                                              spend time in prison or in a labor camp   \n",
       "10                                                         work for or be a servant to   \n",
       "11                                             deliver a warrant or summons to someone   \n",
       "12                           be sufficient; be adequate, either in quality or quantity   \n",
       "13                                                                 do military service   \n",
       "14                                                                           mate with   \n",
       "15                                                              put the ball into play   \n",
       "\n",
       "                                         Lemmas  \\\n",
       "0                              [serve, service]   \n",
       "1                             [serve, function]   \n",
       "2                                       [serve]   \n",
       "3                                       [serve]   \n",
       "4                              [service, serve]   \n",
       "5                                 [serve, help]   \n",
       "6    [serve, serve_up, dish_out, dish_up, dish]   \n",
       "7                                       [serve]   \n",
       "8                           [serve, serve_well]   \n",
       "9                                   [serve, do]   \n",
       "10  [serve, attend_to, wait_on, attend, assist]   \n",
       "11                  [serve, process, swear_out]   \n",
       "12                 [suffice, do, answer, serve]   \n",
       "13                                      [serve]   \n",
       "14                             [serve, service]   \n",
       "15                                      [serve]   \n",
       "\n",
       "                                                                                                                                                                            Examples  \n",
       "0                                                                                                                                                 [his powerful serves won the game]  \n",
       "1    [The tree stump serves as a table, The female students served as a control group, This table would serve very well, His freedom served him well, The table functions as a desk]  \n",
       "2                                                                                        [He served as head of the department for three years, She served in Congress for two terms]  \n",
       "3                                                                                                                                    [The scandal served to increase his popularity]  \n",
       "4                                                                                     [The sewage plant served the neighboring communities, The garage served to shelter his horses]  \n",
       "5                                                                                                                       [I served him three times, and after that he helped himself]  \n",
       "6                                                                     [We serve meals for the homeless, She dished out the soup at 8 P.M., The entertainers served up a lively show]  \n",
       "7                                                                                                             [She served the art of music, He served the church, serve the country]  \n",
       "8                                                  [Art serves commerce, Their interests are served, The lake serves recreation, The President's wisdom has served the country well]  \n",
       "9                                                                                                                                                [He did six years for embezzlement]  \n",
       "10  [May I serve you?, She attends the old lady in the wheelchair, Can you wait on our table, please?, Is a salesperson assisting you?, The minister served the King for many years]  \n",
       "11                                                                                                                                                 [He was processed by the sheriff]  \n",
       "12                     [A few words would answer, This car suits my purpose well, Will $100 do?, A 'B' grade doesn't suffice to get me into medical school, Nothing else will serve]  \n",
       "13                                                                                                     [She served in Vietnam, My sons never served, because they are short-sighted]  \n",
       "14                                                                                                                            [male animals serve the females for breeding purposes]  \n",
       "15                                                                                                                                                   [It was Agassi's turn to serve]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_syn_df(\"serve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synonyms and Antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonym(word):\n",
    "    synonym = []\n",
    "    for syn in wn.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonym.append(lemma.name())\n",
    "            \n",
    "    #get the unique words only\n",
    "    return list(set(synonym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well-chosen', 'glad', 'felicitous', 'happy']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_synonym(\"happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_antonym(word):\n",
    "    antonym = []\n",
    "    for syn in wn.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            if lemma.antonyms():\n",
    "                antonym.append(lemma.antonyms()[0].name())\n",
    "            \n",
    "    #get the unique words only\n",
    "    return list(set(antonym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unhappy']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_antonym(\"happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('red.n.01'),\n",
       " Synset('red.n.02'),\n",
       " Synset('bolshevik.n.01'),\n",
       " Synset('loss.n.06'),\n",
       " Synset('red.s.01'),\n",
       " Synset('crimson.s.02'),\n",
       " Synset('crimson.s.03')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyponyms and Hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chromatic_color.n.01')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = wn.synset(\"red.n.01\")\n",
    "red.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('blond.n.02'),\n",
       " Synset('blue.n.01'),\n",
       " Synset('brown.n.01'),\n",
       " Synset('complementary_color.n.01'),\n",
       " Synset('green.n.01'),\n",
       " Synset('olive.n.05'),\n",
       " Synset('orange.n.02'),\n",
       " Synset('pastel.n.01'),\n",
       " Synset('pink.n.01'),\n",
       " Synset('purple.n.01'),\n",
       " Synset('red.n.01'),\n",
       " Synset('salmon.n.04'),\n",
       " Synset('yellow.n.01')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chromatic_color = wn.synset(\"chromatic_color.n.01\")\n",
    "chromatic_color.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('meal.n.01')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breakfast = wn.synset(\"breakfast.n.01\")\n",
    "breakfast.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('banquet.n.02'),\n",
       " Synset('bite.n.04'),\n",
       " Synset('breakfast.n.01'),\n",
       " Synset('brunch.n.01'),\n",
       " Synset('buffet.n.02'),\n",
       " Synset('dinner.n.01'),\n",
       " Synset('lunch.n.01'),\n",
       " Synset('mess.n.04'),\n",
       " Synset('nosh-up.n.01'),\n",
       " Synset('picnic.n.03'),\n",
       " Synset('ploughman's_lunch.n.01'),\n",
       " Synset('potluck.n.01'),\n",
       " Synset('refection.n.01'),\n",
       " Synset('square_meal.n.01'),\n",
       " Synset('supper.n.01'),\n",
       " Synset('tea.n.02')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meal = wn.synset(\"meal.n.01\")\n",
    "meal.hyponyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austen = wn.synset(\"austen.n.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_all_hypernyms',\n",
       " '_definition',\n",
       " '_examples',\n",
       " '_frame_ids',\n",
       " '_hypernyms',\n",
       " '_instance_hypernyms',\n",
       " '_iter_hypernym_lists',\n",
       " '_lemma_names',\n",
       " '_lemma_pointers',\n",
       " '_lemmas',\n",
       " '_lexname',\n",
       " '_max_depth',\n",
       " '_min_depth',\n",
       " '_name',\n",
       " '_needs_root',\n",
       " '_offset',\n",
       " '_pointers',\n",
       " '_pos',\n",
       " '_related',\n",
       " '_shortest_hypernym_paths',\n",
       " '_wordnet_corpus_reader',\n",
       " 'also_sees',\n",
       " 'attributes',\n",
       " 'causes',\n",
       " 'closure',\n",
       " 'common_hypernyms',\n",
       " 'definition',\n",
       " 'entailments',\n",
       " 'examples',\n",
       " 'frame_ids',\n",
       " 'hypernym_distances',\n",
       " 'hypernym_paths',\n",
       " 'hypernyms',\n",
       " 'hyponyms',\n",
       " 'in_region_domains',\n",
       " 'in_topic_domains',\n",
       " 'in_usage_domains',\n",
       " 'instance_hypernyms',\n",
       " 'instance_hyponyms',\n",
       " 'jcn_similarity',\n",
       " 'lch_similarity',\n",
       " 'lemma_names',\n",
       " 'lemmas',\n",
       " 'lexname',\n",
       " 'lin_similarity',\n",
       " 'lowest_common_hypernyms',\n",
       " 'max_depth',\n",
       " 'member_holonyms',\n",
       " 'member_meronyms',\n",
       " 'min_depth',\n",
       " 'name',\n",
       " 'offset',\n",
       " 'part_holonyms',\n",
       " 'part_meronyms',\n",
       " 'path_similarity',\n",
       " 'pos',\n",
       " 'region_domains',\n",
       " 'res_similarity',\n",
       " 'root_hypernyms',\n",
       " 'shortest_path_distance',\n",
       " 'similar_tos',\n",
       " 'substance_holonyms',\n",
       " 'substance_meronyms',\n",
       " 'topic_domains',\n",
       " 'tree',\n",
       " 'usage_domains',\n",
       " 'verb_groups',\n",
       " 'wup_similarity']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(austen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('writer.n.01')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austen.instance_hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('ambrose.n.01'),\n",
       " Synset('bach.n.01'),\n",
       " Synset('barber.n.01'),\n",
       " Synset('bartok.n.01'),\n",
       " Synset('beethoven.n.01'),\n",
       " Synset('bellini.n.01'),\n",
       " Synset('berg.n.02'),\n",
       " Synset('berlioz.n.01'),\n",
       " Synset('bernstein.n.01'),\n",
       " Synset('bizet.n.01'),\n",
       " Synset('blitzstein.n.01'),\n",
       " Synset('bloch.n.01'),\n",
       " Synset('borodin.n.01'),\n",
       " Synset('boulez.n.01'),\n",
       " Synset('brahms.n.01'),\n",
       " Synset('britten.n.01'),\n",
       " Synset('bruch.n.01'),\n",
       " Synset('bruckner.n.01'),\n",
       " Synset('byrd.n.01'),\n",
       " Synset('cage.n.03'),\n",
       " Synset('chavez.n.01'),\n",
       " Synset('cherubini.n.01'),\n",
       " Synset('chopin.n.03'),\n",
       " Synset('copland.n.01'),\n",
       " Synset('corelli.n.01'),\n",
       " Synset('couperin.n.01'),\n",
       " Synset('coward.n.02'),\n",
       " Synset('czerny.n.01'),\n",
       " Synset('debussy.n.01'),\n",
       " Synset('delibes.n.01'),\n",
       " Synset('delius.n.01'),\n",
       " Synset('donizetti.n.01'),\n",
       " Synset('dowland.n.01'),\n",
       " Synset('dukas.n.01'),\n",
       " Synset('dvorak.n.01'),\n",
       " Synset('elgar.n.01'),\n",
       " Synset('enesco.n.01'),\n",
       " Synset('falla.n.01'),\n",
       " Synset('franck.n.01'),\n",
       " Synset('gershwin.n.02'),\n",
       " Synset('glinka.n.01'),\n",
       " Synset('gluck.n.01'),\n",
       " Synset('gounod.n.01'),\n",
       " Synset('grainger.n.01'),\n",
       " Synset('grieg.n.01'),\n",
       " Synset('halevy.n.01'),\n",
       " Synset('handel.n.01'),\n",
       " Synset('handy.n.01'),\n",
       " Synset('haydn.n.01'),\n",
       " Synset('hindemith.n.01'),\n",
       " Synset('honegger.n.01'),\n",
       " Synset('humperdinck.n.01'),\n",
       " Synset('ibert.n.01'),\n",
       " Synset('ives.n.01'),\n",
       " Synset('joachim.n.01'),\n",
       " Synset('joplin.n.02'),\n",
       " Synset('kachaturian.n.01'),\n",
       " Synset('kern.n.01'),\n",
       " Synset('khachaturian.n.01'),\n",
       " Synset('lambert.n.02'),\n",
       " Synset('lasso.n.01'),\n",
       " Synset('ledbetter.n.01'),\n",
       " Synset('lehar.n.01'),\n",
       " Synset('liszt.n.01'),\n",
       " Synset('lloyd_webber.n.01'),\n",
       " Synset('loewe.n.01'),\n",
       " Synset('lully.n.02'),\n",
       " Synset('macdowell.n.01'),\n",
       " Synset('mahler.n.01'),\n",
       " Synset('massenet.n.01'),\n",
       " Synset('mendelssohn.n.01'),\n",
       " Synset('menotti.n.01'),\n",
       " Synset('meyerbeer.n.01'),\n",
       " Synset('milhaud.n.01'),\n",
       " Synset('monteverdi.n.01'),\n",
       " Synset('moore.n.01'),\n",
       " Synset('mozart.n.01'),\n",
       " Synset('mussorgsky.n.01'),\n",
       " Synset('nielsen.n.01'),\n",
       " Synset('offenbach.n.01'),\n",
       " Synset('orbison.n.01'),\n",
       " Synset('palestrina.n.01'),\n",
       " Synset('piston.n.01'),\n",
       " Synset('porter.n.04'),\n",
       " Synset('poulenc.n.01'),\n",
       " Synset('prokofiev.n.01'),\n",
       " Synset('puccini.n.01'),\n",
       " Synset('purcell.n.01'),\n",
       " Synset('rachmaninoff.n.01'),\n",
       " Synset('rameau.n.01'),\n",
       " Synset('ravel.n.01'),\n",
       " Synset('reich.n.03'),\n",
       " Synset('respighi.n.01'),\n",
       " Synset('rimsky-korsakov.n.01'),\n",
       " Synset('rodgers.n.01'),\n",
       " Synset('romberg.n.01'),\n",
       " Synset('rossini.n.01'),\n",
       " Synset('rubinstein.n.02'),\n",
       " Synset('saint-saens.n.01'),\n",
       " Synset('satie.n.01'),\n",
       " Synset('schnabel.n.01'),\n",
       " Synset('schonberg.n.01'),\n",
       " Synset('schubert.n.01'),\n",
       " Synset('schumann.n.01'),\n",
       " Synset('schumann.n.02'),\n",
       " Synset('scriabin.n.01'),\n",
       " Synset('segovia.n.01'),\n",
       " Synset('sessions.n.01'),\n",
       " Synset('shostakovich.n.01'),\n",
       " Synset('sibelius.n.01'),\n",
       " Synset('smetana.n.01'),\n",
       " Synset('sondheim.n.01'),\n",
       " Synset('sousa.n.01'),\n",
       " Synset('strauss.n.01'),\n",
       " Synset('strauss.n.02'),\n",
       " Synset('strauss.n.03'),\n",
       " Synset('stravinsky.n.01'),\n",
       " Synset('sullivan.n.05'),\n",
       " Synset('tallis.n.01'),\n",
       " Synset('taylor.n.01'),\n",
       " Synset('tchaikovsky.n.01'),\n",
       " Synset('telemann.n.01'),\n",
       " Synset('thomson.n.01'),\n",
       " Synset('varese.n.01'),\n",
       " Synset('vaughan_williams.n.01'),\n",
       " Synset('verdi.n.01'),\n",
       " Synset('villa-lobos.n.01'),\n",
       " Synset('vivaldi.n.01'),\n",
       " Synset('wagner.n.02'),\n",
       " Synset('walton.n.01'),\n",
       " Synset('weber.n.05'),\n",
       " Synset('weill.n.01'),\n",
       " Synset('wolf.n.02')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composer = wn.synset(\"composer.n.01\")\n",
    "composer.instance_hyponyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos tagging with NLTK\n",
    "def pos_tag_sentence_nltk(sentence):\n",
    "    pos_tags = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "    return pd.DataFrame(pos_tags, columns=[\"Token\", \"POS Tag\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Token</th>\n",
       "      <td>Europe</td>\n",
       "      <td>imports</td>\n",
       "      <td>more</td>\n",
       "      <td>diesel</td>\n",
       "      <td>from</td>\n",
       "      <td>MidEast</td>\n",
       "      <td>,</td>\n",
       "      <td>Asia</td>\n",
       "      <td>to</td>\n",
       "      <td>replace</td>\n",
       "      <td>Russia</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS Tag</th>\n",
       "      <td>NNP</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>RBR</td>\n",
       "      <td>NN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>,</td>\n",
       "      <td>NNP</td>\n",
       "      <td>TO</td>\n",
       "      <td>VB</td>\n",
       "      <td>NNP</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0        1     2       3     4        5  6     7   8        9   \\\n",
       "Token    Europe  imports  more  diesel  from  MidEast  ,  Asia  to  replace   \n",
       "POS Tag     NNP      VBZ   RBR      NN    IN      NNP  ,   NNP  TO       VB   \n",
       "\n",
       "             10 11  \n",
       "Token    Russia  .  \n",
       "POS Tag     NNP  .  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag_sentence_nltk(\"Europe imports more diesel from MidEast, Asia to replace Russia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Token</th>\n",
       "      <td>europe</td>\n",
       "      <td>imports</td>\n",
       "      <td>more</td>\n",
       "      <td>diesel</td>\n",
       "      <td>from</td>\n",
       "      <td>mideast</td>\n",
       "      <td>,</td>\n",
       "      <td>asia</td>\n",
       "      <td>to</td>\n",
       "      <td>replace</td>\n",
       "      <td>russia</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS Tag</th>\n",
       "      <td>NN</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>RBR</td>\n",
       "      <td>NN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NN</td>\n",
       "      <td>,</td>\n",
       "      <td>NN</td>\n",
       "      <td>TO</td>\n",
       "      <td>VB</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0        1     2       3     4        5  6     7   8        9   \\\n",
       "Token    europe  imports  more  diesel  from  mideast  ,  asia  to  replace   \n",
       "POS Tag      NN      VBZ   RBR      NN    IN       NN  ,    NN  TO       VB   \n",
       "\n",
       "             10 11  \n",
       "Token    russia  .  \n",
       "POS Tag      NN  .  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#notice that Europe, MidEast, Russia changed from NNP to NN\n",
    "#i.e. Proper Noun (name of place/person) to Noun\n",
    "pos_tag_sentence_nltk(\"Europe imports more diesel from MidEast, Asia to replace Russia.\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos tagging with Spacy\n",
    "def pos_tag_sentence_spacy(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    sentence_nlp = nlp(sentence)\n",
    "    pos_tags = [(word, word.tag_, word.pos_) for word in sentence_nlp]\n",
    "    return pd.DataFrame(pos_tags, columns=[\"Token\", \"POS Tag\", \"Tag Type\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Token</th>\n",
       "      <td>Europe</td>\n",
       "      <td>imports</td>\n",
       "      <td>more</td>\n",
       "      <td>diesel</td>\n",
       "      <td>from</td>\n",
       "      <td>MidEast</td>\n",
       "      <td>,</td>\n",
       "      <td>Asia</td>\n",
       "      <td>to</td>\n",
       "      <td>replace</td>\n",
       "      <td>Russia</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS Tag</th>\n",
       "      <td>NNP</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>JJR</td>\n",
       "      <td>NN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>,</td>\n",
       "      <td>NNP</td>\n",
       "      <td>TO</td>\n",
       "      <td>VB</td>\n",
       "      <td>NNP</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag Type</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PART</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1     2       3     4        5      6      7     8   \\\n",
       "Token     Europe  imports  more  diesel  from  MidEast      ,   Asia    to   \n",
       "POS Tag      NNP      VBZ   JJR      NN    IN      NNP      ,    NNP    TO   \n",
       "Tag Type   PROPN     VERB   ADJ    NOUN   ADP    PROPN  PUNCT  PROPN  PART   \n",
       "\n",
       "               9       10     11  \n",
       "Token     replace  Russia      .  \n",
       "POS Tag        VB     NNP      .  \n",
       "Tag Type     VERB   PROPN  PUNCT  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag_sentence_spacy(\"Europe imports more diesel from MidEast, Asia to replace Russia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Token</th>\n",
       "      <td>europe</td>\n",
       "      <td>imports</td>\n",
       "      <td>more</td>\n",
       "      <td>diesel</td>\n",
       "      <td>from</td>\n",
       "      <td>mideast</td>\n",
       "      <td>,</td>\n",
       "      <td>asia</td>\n",
       "      <td>to</td>\n",
       "      <td>replace</td>\n",
       "      <td>russia</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS Tag</th>\n",
       "      <td>NNP</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>JJR</td>\n",
       "      <td>NN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>,</td>\n",
       "      <td>NNP</td>\n",
       "      <td>TO</td>\n",
       "      <td>VB</td>\n",
       "      <td>NNP</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag Type</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PART</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1     2       3     4        5      6      7     8   \\\n",
       "Token     europe  imports  more  diesel  from  mideast      ,   asia    to   \n",
       "POS Tag      NNP      VBZ   JJR      NN    IN      NNP      ,    NNP    TO   \n",
       "Tag Type   PROPN     VERB   ADJ    NOUN   ADP    PROPN  PUNCT  PROPN  PART   \n",
       "\n",
       "               9       10     11  \n",
       "Token     replace  russia      .  \n",
       "POS Tag        VB     NNP      .  \n",
       "Tag Type     VERB   PROPN  PUNCT  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spacy still work well even after we convert to lower case\n",
    "pos_tag_sentence_spacy(\"Europe imports more diesel from MidEast, Asia to replace Russia.\".lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordNet Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_sentence(sentence):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    lemmatized_sentence = \" \".join(lemmatizer.lemmatize(w) for w in words)\n",
    "    return lemmatized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Europe import more diesel from MidEast , Asia to replace Russia .'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_sentence(\"Europe imports more diesel from MidEast, Asia to replace Russia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He went home happily .'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_sentence(\"He went home happily.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He colored the picture nicely'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colored is not converted properly to color\n",
    "#not taking into account the POS Tags!\n",
    "lemmatize_sentence(\"He colored the picture nicely\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('colored', 'VBN')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag([\"colored\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wn.ADJ,\n",
    "                \"N\": wn.NOUN,\n",
    "                \"V\": wn.VERB,\n",
    "                \"R\": wn.ADV}\n",
    "\n",
    "    #if can't find a match, just treat it as noun\n",
    "    return tag_dict.get(tag, wn.NOUN)\n",
    "\n",
    "def lemmatize_sentence_with_pos_tagging(sentence):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    lemmatized_sentence = \" \".join(lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in words)\n",
    "    return lemmatized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He color the picture nicely .'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_sentence_with_pos_tagging(\"He colored the picture nicely.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chinese millionaire to double by 2026 , Credit Suisse say , despite slow economy'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_sentence_with_pos_tagging(\"Chinese millionaires to double by 2026, Credit Suisse says, despite slowing economy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He go home happily'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_sentence_with_pos_tagging(\"He went home happily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19160/3909579629.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"en_core_web_sm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Europe import more diesel from MidEast , Asia to replace Russia .'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Europe imports more diesel from MidEast, Asia to replace Russia.\")\n",
    "\" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he color the picture nicely .'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"He colored the picture nicely.\")\n",
    "\" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Text Normalization : Remove Accented Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some Accented text'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "remove_accented_chars('Sm ccntd txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other NLP Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Parsing / Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used to identify entities. Basically looking for **noun phrases**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The little brown bear\n",
      "the big black dog\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"The little brown bear was fighting the big black dog\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More difficult to get the noun phrase chunks (compared to Spacy) but provides a better foundation in NLP as to how things actually work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('brown', 'JJ'),\n",
       " ('bear', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('fighting', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('big', 'JJ'),\n",
       " ('black', 'JJ'),\n",
       " ('dog', 'NN')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentence = nltk.pos_tag(nltk.word_tokenize(\"The little brown bear was fighting the big black dog\"))\n",
    "tagged_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP The/DT little/JJ brown/JJ bear/NN)\n",
      "  was/VBD\n",
      "  fighting/VBG\n",
      "  (NP the/DT big/JJ black/JJ dog/NN))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Tree('S', [Tree('NP', [('The', 'DT'), ('little', 'JJ'), ('brown', 'JJ'), ('bear', 'NN')]), ('was', 'VBD'), ('fighting', 'VBG'), Tree('NP', [('the', 'DT'), ('big', 'JJ'), ('black', 'JJ'), ('dog', 'NN')])])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "  NP: {<DT|PP\\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and noun\n",
    "      {<NNP>+}                # chunk sequences of proper nouns\n",
    "\"\"\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "chunked_sentence = cp.parse(tagged_sentence)\n",
    "print(chunked_sentence)\n",
    "chunked_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "for chunk in chunked_sentence.subtrees(filter = lambda t: t.label() == \"NP\"):\n",
    "    chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('NP', [('The', 'DT'), ('little', 'JJ'), ('brown', 'JJ'), ('bear', 'NN')]),\n",
       " Tree('NP', [('the', 'DT'), ('big', 'JJ'), ('black', 'JJ'), ('dog', 'NN')])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_phrases = []\n",
    "for chunk in chunks:\n",
    "    np = \" \".join(c[0] for c in chunk)\n",
    "    noun_phrases.append(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The little brown bear', 'the big black dog']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognizer (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named Entity Recognizer (NER) is more focused on getting named entities (e.g. Person, Organization, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"WASHINGTON : A top adviser to U.S. Treasury Secretary Janet Yellen will warn on Tuesday that China's foot-dragging on debt relief could burden dozens of low- and middle-income countries with years of debt servicing problems, lower growth and underinvestment.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1 = \"WASHINGTON : A top adviser to U.S. Treasury Secretary Janet Yellen will warn on Tuesday that China's foot-dragging on debt relief could burden dozens of low- and middle-income countries with years of debt servicing problems, lower growth and underinvestment.\"\n",
    "sentence1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| NE Type | Examples |\n",
    "| ------- | ---------|\n",
    "| ORGANIZATION \t| Georgia-Pacific Corp., WHO |\n",
    "| PERSON \t| Eddy Bonte, President Obama |\n",
    "| LOCATION \t| Murray River, Mount Everest |\n",
    "| DATE \t | June, 2008-06-29 |\n",
    "| TIME \t| two fifty a m, 1:30 p.m. ||\n",
    "| MONEY | \t175 million Canadian Dollars, GBP 10.40 |\n",
    "| PERCENT  |\ttwenty pct, 18.75 % |\n",
    "| FACILITY |\tWashington Monument, Stonehenge |\n",
    "| GPE \t| South East Asia, Midlothian |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPE WASHINGTON\n",
      "GPE U.S.\n",
      "ORGANIZATION Treasury\n",
      "PERSON Janet Yellen\n",
      "GPE China\n"
     ]
    }
   ],
   "source": [
    "#Using NLTK\n",
    "for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sentence1))):\n",
    "    if hasattr(chunk, \"label\"):\n",
    "        print(chunk.label(), \" \".join(c[0] for c in chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WASHINGTON 0 10 GPE\n",
      "U.S. 30 34 GPE\n",
      "Treasury 35 43 ORG\n",
      "Janet Yellen 54 66 PERSON\n",
      "Tuesday 80 87 DATE\n",
      "China 93 98 GPE\n",
      "dozens 143 149 CARDINAL\n",
      "years 191 196 DATE\n"
     ]
    }
   ],
   "source": [
    "#Using Spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(sentence1)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
